{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLADE DEMO\n",
    "\n",
    "synopsis\n",
    "- Load modules\n",
    "- Example simulation data generation (some variability options; multiple samples)\n",
    "- Application of BLADE\n",
    "- Performance evaluation (both cellular fraction/purification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.relpath('../python/')) # location of python script\n",
    "\n",
    "from BLADE import BLADE_framework as BLADE #to be changed\n",
    "import numpy as np\n",
    "from numpy import transpose as t\n",
    "import itertools\n",
    "import pickle\n",
    "from scipy.optimize import nnls\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of simulation data \n",
    "\n",
    "- Also provide some overview of data (e.g., what is the variability? - both in log-scale and linear scale?)\n",
    "- Allow users to change setting (e.g., number of cell types and samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "Ncells = [5]\n",
    "Ngenes = [500]\n",
    "Nsamples = [20]\n",
    "Noises = [0.25, 0.5, 0.75, 1] #try with less no. of noises [0.1, 0.2, 0.5, 0.75, 1, 1.25, 1.5]\n",
    "\n",
    "\n",
    "simfile = '../simulationdata.pickle'\n",
    "if not os.path.exists(simfile):\n",
    "    Synthetic_data = dict()\n",
    "else:\n",
    "    Synthetic_data = pickle.load(open(simfile, 'rb'))\n",
    "\n",
    "for Ncell, Ngene, Nsample, Noise in itertools.product(\n",
    "    Ncells, Ngenes, Nsamples, Noises\n",
    "            ):\n",
    "    name = str(Ncell) +'_'+ str(Ngene) +'_'+ str(Nsample) +'_'+ str(Noise)\n",
    "    \n",
    "    if not name in list(Synthetic_data.keys()):\n",
    "        Coef = np.random.dirichlet(np.ones(Ncell)*5, Nsample).transpose()\n",
    "        Mu_train = np.random.normal(0, 2, size=(Ngene,Ncell))\n",
    "        Omega_train = np.ones((Ngene,Ncell)) * Noise\n",
    "\n",
    "        X_train = np.random.normal(Mu_train, Omega_train, size=(Nsample, Ngene, Ncell))\n",
    "        Y_train = np.zeros((Ngene, Nsample))\n",
    "        for i in range(Nsample):\n",
    "            Y_train[:,i] = np.log(np.dot(np.exp(X_train[i,:,:]), Coef[:,i])+1)\n",
    "\n",
    "    \n",
    "        Synthetic_data[name] = {\n",
    "            'Coef': Coef,\n",
    "            'Mu' : Mu_train, #signature\n",
    "            'X' : X_train, #highres\n",
    "            'Y' : Y_train,\n",
    "            'Omega' : Omega_train\n",
    "        }\n",
    "\n",
    "        \n",
    "with open(simfile, 'wb') as fp:\n",
    "    pickle.dump(Synthetic_data, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLADE application\n",
    "- configuration of parameters\n",
    "- running BLADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'Alpha': [1],\n",
    "    'Alpha0': [0.1, 0.5, 1],\n",
    "    'Kappa0': [1, 0.5, 0.1],\n",
    "    'SigmaY': [0.1, 0.5]\n",
    "}\n",
    "Nrep=3\n",
    "Nrepfinal=5\n",
    "Njob=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/BLADE_outcome_5_500_20_0.25.pickle\n",
      "all of 500 genes are used for optimization.\n",
      "Number of samples used: 5 out of 20 samples.\n",
      "Initialization with Support vector regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   4 out of  20 | elapsed:    2.9s remaining:   11.4s\n",
      "[Parallel(n_jobs=10)]: Done   7 out of  20 | elapsed:    4.5s remaining:    8.3s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  20 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=10)]: Done  13 out of  20 | elapsed:    5.0s remaining:    2.7s\n",
      "[Parallel(n_jobs=10)]: Done  16 out of  20 | elapsed:    5.7s remaining:    1.4s\n",
      "[Parallel(n_jobs=10)]: Done  20 out of  20 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature filtering is done (fsel = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=10)]: Done  41 out of  54 | elapsed:  6.4min remaining:  2.0min\n",
      "[Parallel(n_jobs=10)]: Done  47 out of  54 | elapsed:  6.9min remaining:  1.0min\n",
      "[Parallel(n_jobs=10)]: Done  54 out of  54 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done optimization, elapsed time (min): 10.634846274058024\n",
      "Start inferring per-sample gene expression levels using the entire genes and samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of   5 | elapsed:  3.2min remaining:  4.9min\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   5 | elapsed:  4.0min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/BLADE_outcome_5_500_20_0.5.pickle\n",
      "all of 500 genes are used for optimization.\n",
      "Number of samples used: 5 out of 20 samples.\n",
      "Initialization with Support vector regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:  4.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:  4.9min finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   4 out of  20 | elapsed:   12.7s remaining:   51.0s\n",
      "[Parallel(n_jobs=10)]: Done   7 out of  20 | elapsed:   16.7s remaining:   31.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  20 | elapsed:   22.1s remaining:   22.1s\n",
      "[Parallel(n_jobs=10)]: Done  13 out of  20 | elapsed:   23.9s remaining:   12.9s\n",
      "[Parallel(n_jobs=10)]: Done  16 out of  20 | elapsed:   29.9s remaining:    7.5s\n",
      "[Parallel(n_jobs=10)]: Done  20 out of  20 | elapsed:   35.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature filtering is done (fsel = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done  41 out of  54 | elapsed:  4.4min remaining:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done  47 out of  54 | elapsed:  4.9min remaining:   43.5s\n",
      "[Parallel(n_jobs=10)]: Done  54 out of  54 | elapsed:  5.9min finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done optimization, elapsed time (min): 5.907001515229543\n",
      "Start inferring per-sample gene expression levels using the entire genes and samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   5 | elapsed:  1.1min remaining:   44.5s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:  3.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/BLADE_outcome_5_500_20_0.75.pickle\n",
      "all of 500 genes are used for optimization.\n",
      "Number of samples used: 5 out of 20 samples.\n",
      "Initialization with Support vector regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   4 out of  20 | elapsed:    1.2s remaining:    4.7s\n",
      "[Parallel(n_jobs=10)]: Done   7 out of  20 | elapsed:    1.5s remaining:    2.7s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  20 | elapsed:    2.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=10)]: Done  13 out of  20 | elapsed:    2.6s remaining:    1.4s\n",
      "[Parallel(n_jobs=10)]: Done  16 out of  20 | elapsed:    3.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=10)]: Done  20 out of  20 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature filtering is done (fsel = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=10)]: Done  41 out of  54 | elapsed:  3.2min remaining:  1.0min\n",
      "[Parallel(n_jobs=10)]: Done  47 out of  54 | elapsed:  3.7min remaining:   33.2s\n",
      "[Parallel(n_jobs=10)]: Done  54 out of  54 | elapsed:  5.0min finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done optimization, elapsed time (min): 4.998662928740184\n",
      "Start inferring per-sample gene expression levels using the entire genes and samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   2 out of   5 | elapsed:   37.2s remaining:   55.8s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   5 | elapsed:   38.3s remaining:   25.6s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:   51.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:   51.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/BLADE_outcome_5_500_20_1.pickle\n",
      "all of 500 genes are used for optimization.\n",
      "Number of samples used: 5 out of 20 samples.\n",
      "Initialization with Support vector regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   4 out of  20 | elapsed:    0.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=10)]: Done   7 out of  20 | elapsed:    0.6s remaining:    1.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  20 | elapsed:    0.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=10)]: Done  13 out of  20 | elapsed:    0.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=10)]: Done  16 out of  20 | elapsed:    1.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=10)]: Done  20 out of  20 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature filtering is done (fsel = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=10)]: Done  41 out of  54 | elapsed:  4.3min remaining:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done  47 out of  54 | elapsed:  4.9min remaining:   43.9s\n",
      "[Parallel(n_jobs=10)]: Done  54 out of  54 | elapsed:  6.0min finished\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done optimization, elapsed time (min): 6.017038981119792\n",
      "Start inferring per-sample gene expression levels using the entire genes and samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   2 out of   5 | elapsed:   35.7s remaining:   53.6s\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   5 | elapsed:   36.2s remaining:   24.1s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:   43.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:   43.3s finished\n"
     ]
    }
   ],
   "source": [
    "for Ncell, Ngene, Nsample, Noise in itertools.product(\n",
    "    Ncells, Ngenes, Nsamples, Noises,\n",
    "                ):\n",
    "\n",
    "    name = str(Ncell) +'_'+ str(Ngene) +'_'+ str(Nsample) +'_'+ str(Noise)\n",
    "    outfile = '../data/BLADE_outcome_' + name + '.pickle'\n",
    "\n",
    "    print('creating ' + outfile)\n",
    "    Y = Synthetic_data[name]['Y']\n",
    "    mean = Synthetic_data[name]['Mu']\n",
    "    sd = Synthetic_data[name]['Omega']\n",
    "    \n",
    "    Ind_sample = [True]*5 + [False]*(Nsample - 5)\n",
    "    Marker_Index = [True] * Ngene\n",
    "    \n",
    "    final_obj, best_obj, best_set, outs = BLADE(\n",
    "            mean, sd, np.exp(Y)-1, Marker_Index, Ind_sample,\n",
    "            pars['Alpha'], pars['Alpha0'], pars['Kappa0'], pars['SigmaY'],\n",
    "            Nrep=Nrep, Njob=Njob, Nrepfinal=Nrepfinal, fsel=0)\n",
    "        \n",
    "    pickle.dump(\n",
    "            {\n",
    "                'final_obj': final_obj,\n",
    "                'best_obj': best_obj,\n",
    "                'best_set': best_set,\n",
    "                'outs' : outs,\n",
    "                'pars' : pars\n",
    "            },\n",
    "            open(outfile, 'wb')\n",
    "    )\n",
    "    \n",
    "#37min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of NNLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/NNLS_outcome_5_500_20_0.25.pickle\n",
      "creating ../data/NNLS_outcome_5_500_20_0.5.pickle\n",
      "creating ../data/NNLS_outcome_5_500_20_0.75.pickle\n",
      "creating ../data/NNLS_outcome_5_500_20_1.pickle\n"
     ]
    }
   ],
   "source": [
    "for Ncell, Ngene, Nsample, Noise in itertools.product(\n",
    "    Ncells, Ngenes, Nsamples, Noises,\n",
    "                ):\n",
    "\n",
    "    name = str(Ncell) +'_'+ str(Ngene) +'_'+ str(Nsample) +'_'+ str(Noise)\n",
    "    outfile = '../data/NNLS_outcome_' + name + '.pickle'\n",
    "\n",
    "    if not os.path.exists(outfile):\n",
    "        \n",
    "        print('creating ' + outfile)\n",
    "        Y = Synthetic_data[name]['Y']\n",
    "        mean = Synthetic_data[name]['Mu']\n",
    "        \n",
    "        NNLS_mat = np.zeros(Synthetic_data[name]['Coef'].shape)\n",
    "        for i in range(Nsample):\n",
    "            NNLS_mat[:,i] = nnls(np.exp(mean)-1, np.exp(Y[:,i])-1)[0]\n",
    "        \n",
    "        pickle.dump(\n",
    "            {\n",
    "                'Fraction': NNLS_mat\n",
    "            },\n",
    "            open(outfile, 'wb')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ../data/SVR_outcome_5_500_20_0.25.pickle\n",
      "creating ../data/SVR_outcome_5_500_20_0.5.pickle\n",
      "creating ../data/SVR_outcome_5_500_20_0.75.pickle\n",
      "creating ../data/SVR_outcome_5_500_20_1.pickle\n"
     ]
    }
   ],
   "source": [
    "for Ncell, Ngene, Nsample, Noise in itertools.product(\n",
    "    Ncells, Ngenes, Nsamples, Noises,\n",
    "                ):\n",
    "\n",
    "    name = str(Ncell) +'_'+ str(Ngene) +'_'+ str(Nsample) +'_'+ str(Noise)\n",
    "    outfile = '../data/SVR_outcome_' + name + '.pickle'\n",
    "\n",
    "    if not os.path.exists(outfile):\n",
    "        \n",
    "        print('creating ' + outfile)\n",
    "        Y = Synthetic_data[name]['Y']\n",
    "        X = Synthetic_data[name]['Mu']\n",
    "   \n",
    "        # estimate fraction\n",
    "        SVRcoef = np.zeros((Ncell, Nsample))\n",
    "        Selcoef = np.zeros((Ngene, Nsample))\n",
    "        Nus = [0.25, 0.5, 0.75]\n",
    "        for i in range(Nsample):\n",
    "            sols = [NuSVR(kernel='linear', nu=nu).fit(X,Y[:,i]) for nu in Nus]\n",
    "            RMSE = [mse(sol.predict(X), Y[:,i]) for sol in sols]\n",
    "            Selcoef[sols[np.argmin(RMSE)].support_, i] = 1\n",
    "            SVRcoef[:,i] = np.maximum(sols[np.argmin(RMSE)].coef_,0)\n",
    "            \n",
    "           \n",
    "        # estimate per-cell expression\n",
    "        NNLS_mat = np.zeros((Ngene, Ncell))\n",
    "        for g in range(Ngene):\n",
    "            NNLS_mat[g,:] = nnls(np.transpose(SVRcoef), Y[g,:])[0]\n",
    "        \n",
    "        pickle.dump(\n",
    "            {\n",
    "                'Fraction' : SVRcoef,\n",
    "                'Signature': NNLS_mat\n",
    "             },\n",
    "            open(outfile, 'wb')\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pd.DataFrame()\n",
    "outcome_summary = pd.DataFrame()\n",
    "outcome_Absolute = pd.DataFrame()\n",
    "\n",
    "outcome_svr = pd.DataFrame()\n",
    "outcome_summary_svr = pd.DataFrame()\n",
    "outcome_Absolute_svr = pd.DataFrame()\n",
    "\n",
    "for Ncell, Ngene, Nsample, Noise in itertools.product(\n",
    "    Ncells, Ngenes, Nsamples, Noises,\n",
    "                ):\n",
    "\n",
    "    name = str(Ncell) +'_'+ str(Ngene) +'_'+ str(Nsample) +'_'+ str(Noise)\n",
    "    outfile = '../data/BLADE_outcome_' + name + '.pickle'\n",
    "    BLADE = pickle.load(open(outfile, 'rb'))\n",
    "    outfile_SVR = '../data/SVR_outcome_' + name + '.pickle'\n",
    "    SVR = pickle.load(open(outfile_SVR, 'rb'))\n",
    "    \n",
    "    #Loading test data\n",
    "    Y = np.array(Synthetic_data[name]['Y'])     \n",
    "    mean = np.array(Synthetic_data[name]['Mu'])\n",
    "    sd = np.array(Synthetic_data[name]['Omega'])\n",
    "    X = np.array(Synthetic_data[name]['X'])\n",
    "    fraction = np.array(Synthetic_data[name]['Coef'])\n",
    "    \n",
    "    # Measuring performance of BLADE\n",
    "    obj = BLADE['final_obj']\n",
    "    BLADE_Y = np.log(obj.ExpQ(obj.Nu, obj.Beta, obj.Omega))\n",
    "    BLADE_X = obj.Nu #highres purification\n",
    "    BLADE_M = np.mean(obj.Nu, 0) #group mode\n",
    "    BLADE_F = t(obj.ExpF(obj.Beta)) \n",
    "        \n",
    "    #### GROUP MODE BLADE ####\n",
    "    CorsNu = [np.corrcoef(mean[:,i], BLADE_M[:,i], rowvar=True)[0,1] for i in range(Ncell)]\n",
    "   \n",
    "    Cors = [np.corrcoef(BLADE_F[i,:], fraction[i,:], rowvar=True)[0,1] for i in range(Ncell)]\n",
    "    row = pd.DataFrame(np.array(([name]*Ncell, Cors, CorsNu)).transpose(),\n",
    "                    columns = ['name', 'Correlation', 'CorrelationNu'])\n",
    "    outcome = outcome.append(row, ignore_index=True)\n",
    "    mCors = np.mean(Cors)\n",
    "    Cors = [np.corrcoef(BLADE_F[:,i], fraction[:,i], rowvar=True)[0,1] for i in range(Nsample)]\n",
    "    row = pd.DataFrame(np.array(([name]*Nsample, Cors)).transpose(),\n",
    "                    columns = ['name', 'Correlation'])\n",
    "    outcome_Absolute = outcome_Absolute.append(row, ignore_index=True)\n",
    "    row = pd.DataFrame(np.array((name, mCors, np.mean(Cors), np.mean(CorsNu))),\n",
    "                    index = ['name', 'Correlation', 'AbsCorrelation', 'CorrelationNu'])\n",
    "    outcome_summary = outcome_summary.append(row.transpose(), ignore_index=True)\n",
    "    \n",
    "    #### GROUP MODE SVR ####\n",
    "\n",
    "    \n",
    "    # Measuring performance of SVR\n",
    "    SVR_M = SVR['Signature']\n",
    "    SVR_F = SVR['Fraction'] \n",
    "    \n",
    "    CorsNu_SVR = [np.corrcoef(SVR_M[:,i], mean[:,i], rowvar=True)[0,1] for i in range(Ncell)] #signature\n",
    "   \n",
    "    Cors_SVR = [np.corrcoef(SVR_F[i,:], fraction[i,:], rowvar=True)[0,1] for i in range(Ncell)]\n",
    "    row_SVR = pd.DataFrame(np.array(([name]*Ncell, Cors_SVR, CorsNu_SVR)).transpose(),\n",
    "                    columns = ['name', 'Correlation_SVR', 'CorrelationNu_SVR'])\n",
    "    outcome_svr = outcome_svr.append(row_SVR, ignore_index=True)\n",
    "    mCors_SVR = np.mean(Cors_SVR)\n",
    "    Cors_SVR = [np.corrcoef(SVR_F[:,i], fraction[:,i], rowvar=True)[0,1] for i in range(Nsample)]\n",
    "    row_SVR = pd.DataFrame(np.array(([name]*Nsample, Cors_SVR)).transpose(),\n",
    "                    columns = ['name', 'Correlation_SVR'])\n",
    "    outcome_Absolute_svr = outcome_Absolute_svr.append(row, ignore_index=True)\n",
    "    row_SVR = pd.DataFrame(np.array((name, mCors_SVR, np.mean(Cors_SVR), np.mean(CorsNu_SVR))),\n",
    "                    index = ['name', 'Correlation_SVR', 'AbsCorrelation_SVR', 'CorrelationNu_SVR'])\n",
    "    outcome_summary_svr = outcome_summary_svr.append(row_SVR.transpose(), ignore_index=True)\n",
    "    \n",
    "    \n",
    "    #### HIGH RESOLUTION ####\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Correlation_SVR</th>\n",
       "      <th>AbsCorrelation_SVR</th>\n",
       "      <th>CorrelationNu_SVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_500_20_0.25</td>\n",
       "      <td>0.9695633796127192</td>\n",
       "      <td>0.8375456340554231</td>\n",
       "      <td>0.7410775660295024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_500_20_0.5</td>\n",
       "      <td>0.9579902345399336</td>\n",
       "      <td>0.8724566427423751</td>\n",
       "      <td>0.7028124751421891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_500_20_0.75</td>\n",
       "      <td>0.9474632527573463</td>\n",
       "      <td>0.9245186273995089</td>\n",
       "      <td>0.6569402832797028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_500_20_1</td>\n",
       "      <td>0.8936043118122873</td>\n",
       "      <td>0.8862554739781775</td>\n",
       "      <td>0.5404904681290625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name     Correlation_SVR  AbsCorrelation_SVR   CorrelationNu_SVR\n",
       "0  5_500_20_0.25  0.9695633796127192  0.8375456340554231  0.7410775660295024\n",
       "1   5_500_20_0.5  0.9579902345399336  0.8724566427423751  0.7028124751421891\n",
       "2  5_500_20_0.75  0.9474632527573463  0.9245186273995089  0.6569402832797028\n",
       "3     5_500_20_1  0.8936043118122873  0.8862554739781775  0.5404904681290625"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_summary_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>AbsCorrelation</th>\n",
       "      <th>CorrelationNu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_500_20_0.25</td>\n",
       "      <td>0.8754087431710029</td>\n",
       "      <td>0.8347977393235728</td>\n",
       "      <td>0.6147385922803164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_500_20_0.5</td>\n",
       "      <td>0.8879910425102059</td>\n",
       "      <td>0.37525846998979195</td>\n",
       "      <td>0.7994345523020032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_500_20_0.75</td>\n",
       "      <td>0.9777040812910036</td>\n",
       "      <td>0.9553118247449653</td>\n",
       "      <td>0.9710773469475434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_500_20_1</td>\n",
       "      <td>0.8681060928283653</td>\n",
       "      <td>0.808611426692601</td>\n",
       "      <td>0.8885837542606441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         Correlation       AbsCorrelation       CorrelationNu\n",
       "0  5_500_20_0.25  0.8754087431710029   0.8347977393235728  0.6147385922803164\n",
       "1   5_500_20_0.5  0.8879910425102059  0.37525846998979195  0.7994345523020032\n",
       "2  5_500_20_0.75  0.9777040812910036   0.9553118247449653  0.9710773469475434\n",
       "3     5_500_20_1  0.8681060928283653    0.808611426692601  0.8885837542606441"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
